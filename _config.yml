# Welcome to Jekyll!
#
# This config file is meant for settings that affect your whole blog, values
# which you are expected to set up once and rarely need to edit after that.
# For technical reasons, this file is *NOT* reloaded automatically when you use
# 'jekyll serve'. If you change this file, please restart the server process.

# Site settings
title: jekyll-theme-hackcss
description: > # this means to ignore newlines until "baseurl:"
  A minimalistic theme for Jekyll, based on hack.css
repository: https://github.com/wemake-services/jekyll-theme-hackcss
baseurl:   # the subpath of your site, e.g. /blog
url:   # the base hostname & protocol for your site  https://wemake-services.github.io

# Build settings
markdown: kramdown

# Sass settings
sass:
  style: compressed

# Theme settings
theme_mode: markdown  # choices are: 'dark', 'standard', 'markdown'

# Customizations
your_name: wemake.services
email: mail@sobolevn.me

navigation:
  - text: Home
    url: /
  - text: About
    url: /docs
  - text: Papers
    url: /examples
  - text: Posts
    url: /posts

projects:
  - name: Learning language through pictures
    description: We propose IMAGINET, a model of learning visually grounded representations of language from coupled textual and visual input. The model consists of two Gated Recurrent Unit networks with shared word embeddings, and uses a multitask objective by receiving a textual description of a scene and trying to concurrently predict its visual representation and the next word i the sentence. Like humans, it acquires meaning representations for individual words from descriptions of visual scenes. Moreover, it learns to effectively use sequential structure in semantic interpretation of multi-word phrases.
    link: https://arxiv.org/abs/1506.03694
    image: http://kadarakos.github.io/img/imagenet.png
  - name: Learning word meanings from images of natural scenes
    description: Children early on face the challenge of learning the meaning of words from noisy and ambiguous contexts. Utterances that guide their learning are emitted in complex scenes rendering the mapping between visual and linguistic cues difficult. We propose a novel computational model of cross-situational word learning that takes images of natural scenes paired with their descriptions as input and incrementally learns probabilistic associations between words and image features. Through a set of experiments we show that the model learns meaning representations that correlate with human similarity judgments, and that given an image of a scene it produces words conceptually related to the image.
    link: https://www.atala.org/IMG/pdf/3-_TAL-_55-3-_AKadar-final.pdf
  - name: Individual variation in the choice of referential form
    description: This study aims to measure the variation between writers in their choices of referential form by collecting and analysing a new and publicly available corpus of referring expressions. The corpus is composed of referring expressions produced by different participants in identical situations. Results, measured in terms of normalized entropy, reveal substantial individual variation. We discuss the problems and prospects of this finding for automatic text generation applications.
    link: http://anthology.aclweb.org/N/N16/N16-1048.pdf

social:
  - service: github
    username: sobolevn
    link: https://github.com/sobolevn
  - service: twitter
    username: sobolevn
    link: https://twitter.com/sobolevn

# Plugins
gems:
  - jekyll-seo-tag
